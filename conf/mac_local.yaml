runtime:
  device: "cpu"
  batch_size: 64
  llm_concurrency: 2

llm:
  provider: "local"             # local / remote / auto
  local:
    model_path: "~/models/phi3-mini.Q4_K_M.gguf"
    server_url: "http://127.0.0.1:1234"
  remote:
    endpoint:  "https://api.openai.com/v1/chat/completions"
    model:     "gpt-4o-mini"

failover:
  f1_drop_threshold: 0.03       # 3pt 以上下落で警告ログ

document_structure:
  preserve_structure: true
  detect_markdown: true
  detect_html: true
  detect_indentation: true
  preserve_headers: true
  preserve_lists: true
  preserve_tables: true
  preserve_code_blocks: true
  min_header_level: 1
  max_header_level: 6
  list_indent_threshold: 2
  preserve_whitespace: true