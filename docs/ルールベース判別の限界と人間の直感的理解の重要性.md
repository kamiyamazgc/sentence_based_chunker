# ルールベース判別の限界と人間の直感的理解の重要性

## 背景

`sentence_based_chunker`プロジェクトの最終目標は、人間が生み出す不定型なテキストを意味的な切れ目で綺麗に分割することです。この過程で、見出しとリストアイテムの判別に関する重要な課題が浮かび上がりました。

## 問題の詳細

### テストケース：iPhone Car Keys記事

選択されたテキストの1行目：
```
Here's Which Vehicles Offer iPhone Car Keys
```

### 現在のsemantic_parser.pyの見出し検出ロジック

```python
header_patterns = [
    r'^#{1,6}\s+',  # Markdown見出し
    r'^\d+\.\s+',   # 番号付き見出し
    r'^[A-Z][^.]*:$'  # 大文字始まりのコロン終了
]
```

### 問題点

このロジックでは、`"Here's Which Vehicles Offer iPhone Car Keys"`は見出しとして認識されません：
- `#` で始まらない
- `1.` のような番号で始まらない  
- `:` で終わらない

そのため、`paragraph`として認識されてしまいます。

## ルールベース判別の限界

### 1. 見出し検出の複雑性

#### 問題のある例1：コロンで終わる行
```
Here's the summary of my opinion:
- It
```
この行は現在のロジックで見出しとして認識されますが、実際には文の途中で終わっています。

#### 問題のある例2：不完全なリスト
```
Today's lunch
Sushi
Sukiyaki
Ice cream
```

改善案のルールでは：
- `Today's lunch` → 見出しとして認識
- `Sushi`, `Sukiyaki`, `Ice cream` → すべて見出しとして認識

これは明らかに間違いで、これらはすべてリストアイテムとして認識されるべきです。

### 2. 定式化の限界

見出しとリストアイテムを区別するためのルールを定式化しようとすると：

```python
def is_likely_header(text: str) -> bool:
    # 完全に大文字の短い行（ただし単語が1-2個程度）
    if text.isupper() and len(text.split()) <= 2:
        return True
    
    # 大文字始まりで、より長い説明的な内容
    if (len(text) > 20 and 
        len(text) < 100 and 
        text[0].isupper() and 
        not text.endswith('.') and
        not text.endswith(',') and
        not text.endswith(';') and
        not text.endswith(':') and
        not text.endswith('...') and
        len(text.split()) > 3):
        return True
    
    return False
```

しかし、このルールでも以下のような例で問題が発生します：

```
Product Features
- Fast performance
- Easy to use
- Reliable
```

`Product Features`は見出しとして正しく認識されるべきですが、単語数が2個なので見出しとして認識されません。

## 人間の直感的理解の重要性

### 1. 文脈による判断

人間は以下の要素を総合的に判断して見出しを認識します：

- **文脈**: 前後の内容との関係
- **意味**: その行が何を表現しているか
- **構造**: 文書全体の構造における役割
- **スタイル**: フォーマットや表現方法

### 2. 曖昧性の処理

同じテキストでも、文脈によって見出しかリストアイテムかが変わります：

```
# 見出しとして正しい例
Here's Which Vehicles Offer iPhone Car Keys
[記事の内容...]

# リストアイテムとして正しい例
Today's lunch:
- Here's Which Vehicles Offer iPhone Car Keys
- Another menu item
```

## 本プログラムの最終目標との整合性

### 目標
人間が生み出す不定型なテキストを意味的な切れ目で綺麗に分割することです。最終的に切り分けたチャンクはLLMで翻訳しますが、LLM目線でもそのようなチャンクが望ましい。

### 現在のアプローチの問題
定式化を進めれば進めるほど、人間がそれに合わせて前処理をしなければならなくなります。

### 望ましいアプローチ
1. **人間の直感的理解を模倣するAI技術の活用**
   - 機械学習による文脈理解
   - 自然言語処理による意味解析
   - 文書構造の学習

2. **柔軟性の確保**
   - 固定されたルールに依存しない
   - 新しいパターンに適応可能
   - 文脈を考慮した判断

3. **前処理不要の設計**
   - 人間が特別な前処理をしなくても動作
   - 自然なテキストをそのまま処理可能
   - 直感的な結果を提供

## 結論

ルールベースの判別には本質的な限界があります。人間の直感的な理解を模倣するためには、より高度なAI技術の活用が必要です。本プログラムの最終目標を達成するためには、固定されたルールではなく、文脈を理解し、意味的に適切な判断を行えるシステムの構築が重要です。

## 今後の方向性

1. **機械学習モデルの導入**
   - 文書構造の学習
   - 文脈理解の向上

2. **自然言語処理技術の活用**
   - 意味解析による判断
   - 文脈依存の理解

3. **人間の直感的理解の模倣**
   - 柔軟な判断基準
   - 適応可能なシステム

これにより、人間が前処理をしなくても、自然なテキストを意味的に適切に分割できるシステムの実現が可能になります。 